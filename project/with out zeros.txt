finding max for test data
processing training data
processing data row: 1000
number of zeros
0
Training with 1512 examples
Testing with 504 examples
evaluating bit	0
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}
Best Score: 0.706349206349
Accuracy: 0.69246031746
             precision    recall  f1-score   support

          0       0.70      0.71      0.71       263
          1       0.68      0.67      0.68       241

avg / total       0.69      0.69      0.69       504

evaluating bit	1
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}
Best Score: 0.699735449735
Accuracy: 0.720238095238
             precision    recall  f1-score   support

          0       0.75      0.75      0.75       285
          1       0.68      0.68      0.68       219

avg / total       0.72      0.72      0.72       504

evaluating bit	2
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}
Best Score: 0.718915343915
Accuracy: 0.708333333333
             precision    recall  f1-score   support

          0       0.74      0.78      0.76       300
          1       0.65      0.60      0.63       204

avg / total       0.71      0.71      0.71       504

evaluating bit	3
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}
Best Score: 0.714285714286
Accuracy: 0.668650793651
             precision    recall  f1-score   support

          0       0.66      0.83      0.73       277
          1       0.69      0.47      0.56       227

avg / total       0.67      0.67      0.66       504

evaluating bit	4
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}
Best Score: 0.751322751323
Accuracy: 0.714285714286
             precision    recall  f1-score   support

          0       0.80      0.77      0.78       337
          1       0.56      0.61      0.59       167

avg / total       0.72      0.71      0.72       504

evaluating bit	5
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}
Best Score: 0.865740740741
Accuracy: 0.827380952381
             precision    recall  f1-score   support

          0       0.83      0.98      0.90       403
          1       0.73      0.22      0.34       101

avg / total       0.81      0.83      0.79       504

evaluating bit	6
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}
Best Score: 0.95171957672
Accuracy: 0.930555555556
             precision    recall  f1-score   support

          0       0.94      0.99      0.96       469
          1       0.50      0.11      0.19        35

avg / total       0.91      0.93      0.91       504

evaluating bit	7
validating RBF svm
Best Params: {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}
Best Score: 0.991402116402
Accuracy: 0.998015873016
D:\WinPython-64bit-2.7.9.4\python-2.7.9.amd64\lib\site-packages\sklearn\metrics\classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
             precision    recall  f1-score   support

          0       1.00      1.00      1.00       503
          1       0.00      0.00      0.00         1

avg / total       1.00      1.00      1.00       504

finalResults:
['00000101', '00001100', '00000000', '00000011', '00011001', '00000011', '00010000', '00011001', '00010100', '00010000', '00000011', '00000111', '00000010', '00001000', '00011000', '00000001', '00000001', '00000100', '00000011', '00010100', '00000101', '00010101', '00000111', '00011000', '00000011', '00000010', '00010010', '00000011', '00010100', '00000100', '00011111', '00000100', '00000101', '00010100', '00000010', '00000111', '00001111', '00000011', '00111000', '00010000', '00010001', '00000100', '00000011', '00010010', '00010100', '00001100', '00000010', '00000110', '00010100', '00111010', '00001000', '00010110', '00000011', '00010110', '00000010', '00000011', '00010100', '00001010', '00010110', '00000111', '00001010', '00011110', '00011010', '00010010', '00001000', '00000111', '00001110', '00001000', '00000100', '00001111', '00000011', '00111000', '00000110', '00001100', '00001111', '00000101', '00010000', '00010100', '00011000', '00011001', '00010100', '00000010', '00000011', '00000011', '00000111', '00001000', '00010000', '00000011', '00010100', '00000011', '00010011', '00001100', '00001100', '00001011', '00000011', '00011000', '00000000', '00011001', '00011000', '00000011', '00001111', '00000011', '00000011', '00000011', '00011000', '00001000', '00000000', '00010100', '00000011', '00111000', '00011000', '00001111', '00000011', '00000011', '00100110', '00000001', '00000000', '00000100', '00000000', '00001010', '00001111', '00001100', '00011101', '00000001', '00000011', '00000101', '01101001', '00010000', '00000111', '00011101', '00000011', '00001000', '00010100', '00010100', '00010110', '00000011', '00010010', '00000101', '00001111', '00110000', '00010101', '00000011', '00000101', '00010100', '00000101', '00000101', '00000101', '00010000', '00010011', '00010000', '00001000', '00010110', '00000111', '00001000', '00000000', '00000011', '00010000', '00010001', '00001010', '00000011', '00010000', '00010000', '00000011', '00000011', '00000101', '00000010', '00001111', '00010100', '00011010', '00000011', '00000011', '00011000', '00010110', '00010010', '00010100', '00001000', '00010000', '00101000', '00111010', '00000100', '00000011', '00000011', '00000011', '00010100', '00010000', '00000100', '00010101', '00001000', '00000101', '00000100', '00001110', '00000010', '00000011', '00000011', '00000111', '00000011', '00000011', '00011000', '01101101', '00010011', '00000101', '00000011', '00011000', '00001010', '00010000', '00001000', '00000001', '00111000', '00011011', '00001101', '00000011', '00010100', '00000010', '00010101', '00000010', '00000011', '00000111', '00010000', '00001101', '00010000', '00001101', '00010000', '01111010', '00000111', '00010100', '00000011', '00011011', '00010100', '00001000', '00000011', '00000011', '00000011', '01101101', '00000011', '00010000', '00000010', '00000011', '00000000', '01110111', '00010101', '00000011', '00000010', '00011110', '00000101', '00010000', '00000011', '00111010', '00111010', '00000100', '00000010', '00001101', '00011000', '00000101', '00000000', '00000011', '00000101', '00010100', '00001010', '00000100', '00000011', '00010100', '00000001', '00010100', '00111000', '00110000', '00100100', '00001000', '00000011', '00011001', '00011010', '00010100', '00001010', '00011010', '00000101', '00000101', '00000101', '00001101', '00000111', '00010110', '00010100', '00000011', '00111001', '00001101', '00000010', '01001001', '00000001', '00000100', '00000011', '00000011', '00011000', '00001010', '00000011', '00000101', '00000011', '00010101', '00010000', '00000000', '00000111', '00000000', '00000000', '00000011', '00001000', '00010100', '00000100', '00010100', '00011110', '00001111', '00000100', '00000000', '00000000', '00000100', '00010000', '00000011', '00010000', '00000101', '00000101', '00000000', '00011100', '00000011', '00000011', '00010010', '00010101', '00011010', '00001000', '00011001', '00001000', '00010100', '00000101', '00010000', '00001101', '00010111', '00000111', '00000101', '00000011', '00000011', '00011001', '00011110', '00011000', '00001101', '00001000', '00001010', '00001010', '00010100', '00000001', '00010010', '00100101', '00111000', '00001010', '00010100', '00010000', '00010001', '00110000', '00011000', '00010110', '01101101', '00000000', '00000101', '00111010', '00001000', '00001001', '00011101', '00000011', '00000000', '00010100', '00000011', '00001011', '00000011', '00000011', '00010100', '00000011', '00000011', '00000101', '00010100', '00000011', '00001000', '00000010', '00000000', '00000000', '01111000', '00011100', '00010010', '00000010', '00000011', '00000101', '00000001', '00001001', '00000100', '00001010', '00010100', '00010100', '00000011', '00000111', '00010000', '00100100', '00000011', '00001000', '00111010', '00000101', '00010010', '00000000', '00010001', '00000111', '00000011', '00010011', '00000011', '00010010', '00010100', '00011100', '00010000', '00010100', '00011100', '00000011', '00010000', '00001101', '00000001', '00000000', '00110000', '00000000', '00001001', '00010000', '00000101', '00011001', '00001100', '00010100', '00000011', '00001101', '00010010', '00001100', '00000001', '00000111', '00011000', '00010000', '00000100', '00000001', '00000011', '00011111', '00000000', '00000011', '00010110', '00000011', '00001010', '00001000', '00010011', '00010100', '00001100', '00001000', '00011110', '00010100', '00011110', '00011001', '00001000', '00001100', '00010000', '00000111', '00000011', '00000010', '00000011', '00001010', '00000010', '00000011', '00010011', '00000011', '00001000', '00001000', '00000000', '00000011', '00010100', '00000101', '00001101', '00010000', '00110000', '00000101', '00000011', '00000011', '00000011', '00001001', '00000100', '00010011', '00001000', '00001010', '00010000', '00010010', '00001101', '00000001', '00000011', '00000001', '00001000', '00000001', '00001000', '00011000', '00001000', '00001111', '00000001', '00000101', '00000111', '00000010', '00000011', '00000101', '00001011', '00000100', '00000101', '00000011', '00000011', '00000011']
final results

D:\WinPython-64bit-2.7.9.4\python-2.7.9.amd64\lib\site-packages\sklearn\metrics\classification.py:960: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
             precision    recall  f1-score   support

          0       0.00      0.00      0.00         0
          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       0.63      0.50      0.56       119
          4       0.00      0.00      0.00         0
          5       0.15      0.10      0.12        48
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0
          8       0.50      0.21      0.29        73
          9       0.00      0.00      0.00         0
         10       0.20      0.11      0.14        27
         11       0.00      0.00      0.00         0
         12       0.00      0.00      0.00         0
         13       0.17      0.14      0.15        14
         14       0.00      0.00      0.00         0
         15       0.50      0.26      0.34        19
         16       0.00      0.00      0.00         0
         17       0.00      0.00      0.00         0
         18       0.00      0.00      0.00         3
         19       0.00      0.00      0.00         0
         20       0.49      0.31      0.38        64
         21       0.00      0.00      0.00         0
         22       0.00      0.00      0.00         0
         23       0.00      0.00      0.00         0
         24       0.00      0.00      0.00         0
         25       0.56      0.45      0.50        11
         26       0.00      0.00      0.00         0
         27       0.00      0.00      0.00         0
         28       0.25      0.25      0.25         4
         29       0.00      0.00      0.00         0
         30       0.50      0.18      0.26        17
         31       0.00      0.00      0.00         0
         36       1.00      0.17      0.29        12
         37       0.00      0.00      0.00         0
         38       1.00      0.50      0.67         2
         40       0.00      0.00      0.00         0
         48       0.60      0.17      0.26        18
         51       0.00      0.00      0.00         7
         56       0.67      0.22      0.33        18
         57       0.00      0.00      0.00         0
         58       0.67      0.31      0.42        13
         73       0.00      0.00      0.00         0
         79       0.00      0.00      0.00         4
        105       0.00      0.00      0.00         0
        109       1.00      0.16      0.27        19
        112       0.00      0.00      0.00         3
        119       0.00      0.00      0.00         0
        120       0.00      0.00      0.00         0
        122       1.00      0.12      0.22         8
        244       0.00      0.00      0.00         1

avg / total       0.51      0.27      0.34       504

Accuracy: 0.271825396825
there were  137  predictions correct that werent 0