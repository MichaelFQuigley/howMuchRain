\documentclass[pdftex,a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{mathtools}
\title{Machine Learning Final Project}
\author{Michael Quigley, Zachary Wilcox}
\date{5/5/15}

\begin{document}
\maketitle
\section{Intro}
\subsection{Problem}
Predict probabilistic distribution of hourly rain given polarimetric radar measurements.
The project attempts to use the probabilistic distribution of rain over a field using data from
polarimetric radar. This allows people to avoid putting rain gauges everywhere. A polarimetric
radar transmits radio wave pulses in both vertical and horizontal orientations allowing the size
of a raindrop to be more easily inferred when compared with Doppler radar.
\subsection{Data}
The data contains derived quantities at a location for a period of an hour from polarimetric
radar. The data is broken up into nineteen columns: "Time To End", "Distance To Radar",
"Composite", "Hybrid Scan", "Hydrometeor Type", "Kdp", "Rain rate from HCAbased
algorithms", "Rain rate from Zdrbased
algorithms", "Rain rate from Kdpbased
algorithms",
"Radar Quality Index", "Reflectivity", "RefelectivtyQC", "RhoHV", "Velocity", "Zdrbased
Log
Water Volume", "Mass Weighted Mean", and "Mass Weighted Standard Deviation".
The columns may have more than one value. This is the case when there are multiple “Times
to End” for one radar and/or there are multiple radar readings for one location. The training
data also contains an expected amount of rain for that data location. The columns may also
contain error values. The error values are as follows: "99000",
"99901",
"99903",
"nan",
"999.0" which indicate the value for that specific element in the row is invalid.




There were two files provided by Kaggle. The train file was train\_2013.csv and the test file was test\_2014.csv. Each row in the files had an id along with all nineteen other columns. The train file had an additional feature called "expected" that was the actual amount of rain measured at the end of the hour.
\subsection{Output file}
Kaggle required another CSV file as the submission. This file had as many rows as the test file. Each row had 70 columns where each column was a number that represented $P(y \le Y)$. The headers of the columns ranged from 0 to 69mm. The value $y$ was the rain accumulation and $Y$ would be the current column's header value. Since this is a cumulative distribution, we decided that the prediction for a certain row in the test file (which is just a total amount of rain in mm for the hour) would be the center of a sigmoid, and the values of this sigmoid would be used to populate the columns in the output file.




\section{Linear Regression}
The linear regression update was of the form:
$$w^{T + 1}_j = w^{T}_j - \gamma^T(w^{T} \cdot x_{i} - y_i)x_{ij}$$
Where $\gamma^T$ is the learning rate for a specific iteration, $i$ is the example number, and $j$ is the feature number. The prediction was of the form:
$$w^{T} \cdot x_{i}.$$
The learning rate was changed after every iteration using the following and was initialized as $\gamma_0$:
$$\gamma^{T + 1} = \frac{\gamma^{T}}{1 + \gamma^{T} / C}$$
Where C is a hyper parameter.




Since the columns had multiple values, the median of the column values was used as the feature value. If the value was invalid, then the median of the valid elements was used.
\subsection{Feature Selection}
Linear regression was a fairly quick algorithm to run on the training set. This means there was a lot of time for experimentation with different feature combinations. The attribute 'HydrometeorType' was dropped. This was just a number that referred to a type of hydrometeor, and there was no obvious reason for this attribute. Keeping it in the set did not seem to improve accuracy by any accuracy metric. Since a distribution over the total amount of rain was the end goal, three new columns were created that were each a product of other columns. These columns roughly represented an estimate for the total amount of rain for a given amount of time. The new columns added were RR1 * TimeToEnd, RR2 * TimeToEnd, and RR3 * TimeToEnd. After this, other attributes were removed individually until accuracy was maximized. The attributes that ended up being removed for the resulting best accuracy were, 'ReflectivityQC', 'HybridScan', 'Velocity', 'Reflectivity', 'Composite', 'HydrometeorType', 'DistanceToRadar', 'Zdr', 'RhoHV', and 'Kdp'. The rain rates and radar quality index seemed to have the most influence on accuracy.




\subsection{Metrics for Accuracy}
Accuracy was measured after the first 100000 elements of the train\_2013.csv train set. The na{\"i}ve metric for accuracy that was initially used was checking to see whether the true label and the prediction were either both non-zero or both zero (0-non0). If one was zero and the other non-zero, then a mistake was counted toward the overall accuracy. This was a good initial metric as it demonstrated that the linear regression algorithm would usually predict zero when the true label was zero, and usually non zero when the true label was non zero. It could be argued that since most of the true labels were zero, a good accuracy could just be achieved by always predicting zero. What is interesting is that most of the true labels that were non zero had a non zero prediction. The problem with this metric is that many of the zero labels also had a very small non zero value. The second metric used for determining accuracy was checking to see whether the difference between the true label and the prediction was greater than some delta ($abs(a - b) > delta$). This delta was chosen to be 0.5.
\subsection{Results}
See Table \ref{table:linAcc}.
  \begin{table}[h]
        {\centering
          \begin{tabular}{|c|c|c|c|c|}
            \hline
             $\gamma_0$ & C & Accuracy Metric & Accuracy (\%) & Kaggle Ranking\\
            \hline
                0.0007 &   0.05        & 0-non0 & 49.33 & 285/305 \\
             \hline
                - &   -        & $abs(a - b) > delta$ & 92.5 & - \\
                  \hline
                0.01 &  100         &  0-non0  & 48.2 & 292/305   ouch... \\
          \hline
                - &  -         & $abs(a - b) > delta$ & 86.4 & - \\
             \hline
          \end{tabular}
          \caption{Linear Regression Results}          
          \label{table:linAcc}}
  \end{table}




\end{document}